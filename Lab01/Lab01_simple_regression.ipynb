{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nielsjdewinter/VU_Data_analysis_Jupyter_labs/blob/main/Lab01_simple_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a800754",
      "metadata": {
        "id": "6a800754"
      },
      "source": [
        "# Lab 01: Correlation and Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4941156d",
      "metadata": {
        "id": "4941156d"
      },
      "source": [
        "Author: **N.J. de Winter** (*n.j.de.winter@vu.nl*)<br>\n",
        "Assitant Professor Vrije Universiteit Amsterdam<br>\n",
        "Statistics and Data Analysis Course"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b877f19",
      "metadata": {
        "id": "9b877f19"
      },
      "source": [
        "## Learning goals:\n",
        "\n",
        "* Get famliar with Python through Jupyter\n",
        "* Understand and apply tools to assess whether two variables are *correlated*\n",
        "* Learn how to apply *regression* analysis to determine the shape of the *relationship* between two variables:\n",
        "    * Simple linear regression (straight line relationship)\n",
        "    * Polynomial regression (curved line relationship)\n",
        "    * Exponental regression (exponentially growing or decaying relationship)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "330446ef",
      "metadata": {
        "id": "330446ef"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "In this lab assignment, you will experiment with the tools in Python used to test correlation and regression.\n",
        "We will start with simple correlation, linear and non-linear regression and work towards multiple and logistic regression in the following Lab assignment.\n",
        "\n",
        "This notebook format makes it possible to include live code in between the text for this assignment. Note that you can also make the assignment by copying the code from the code blocks (marked by `In []`) into your own Python environment (such as Spyder) and run the code there (shortcut: __CTRL + ENTER__ on Windows/Linux and __CMD + ENTER__ on Mac). Working in this Jupyter notebook probably helps you to keep your code more organized."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9e83f94",
      "metadata": {
        "id": "b9e83f94"
      },
      "source": [
        "We start each session of Python (and Jupyter) by importing the *packages* we need. We will also use the command `%matplotlib inline` to make it possible to add plots in between our text output. To do so, run the code in the cell below using __CTRL + ENTER__ on Windows/Linux or __CMD + ENTER__ on Mac:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "645b0a6f",
      "metadata": {
        "id": "645b0a6f"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import pandas as pd # The 'pandas' package helps us to import and manage data\n",
        "import scipy.stats as stats # The 'scipy' package contains statistical formulas we will need\n",
        "import statsmodels.formula.api as smf # The 'statsmodels' package contains the functions needed to do regressions\n",
        "from matplotlib import pyplot as plt # The 'matplotlib' package contains tools needed to plot our data and results"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e56cb6b8",
      "metadata": {
        "id": "e56cb6b8"
      },
      "source": [
        "Running the code above should not immediately yield a visible result, but it loads the functions you will need later into Python. If done correctly, you should see `In [1]` left of the cell above (`In [*]` means the kernel is still processing your code). Note also that the text behind the `#` sign is not part of the code, but lists comments that show what the code does. This is a very handy way to keep your code organized and make sure you remember later on what your code does!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e58ef7c0",
      "metadata": {
        "id": "e58ef7c0"
      },
      "source": [
        "Now we will load the dataset you will need for this exercise using the code below. Note that for this to work, you will need to place the datafile (`Lab01a.csv`) in the same folder as this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b00c298",
      "metadata": {
        "id": "2b00c298"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('Lab01a.csv') # Load the data for this assignment into Python and in the Jupyter environment."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7003a23a",
      "metadata": {
        "id": "7003a23a"
      },
      "source": [
        "If you run the code of this notebook in your own Python environment, you first need to specify the working directory and then load the data using a slightly different command. The statement `'<Direction to folder containing dataset>'` should be replaced with the directory of the folder on your PC, e.g.: `C:/MyName/Documents/Statistics_and_Data_Analysis/Lab01/`.\n",
        "\n",
        "WARNING: The code below does not need to be run if you are working in Jupyter. Only run it in Spyder if you use it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34a78605",
      "metadata": {
        "id": "34a78605"
      },
      "outputs": [],
      "source": [
        "wdir = '<Direction to folder containing dataset>' # Set your working directory to the folder which contains the data\n",
        "df = pd.read_csv(wdir + 'Lab01a.csv') # Load the data for this assignment from your own instance of Python."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "529a1285",
      "metadata": {
        "id": "529a1285"
      },
      "source": [
        "Now let's visualize our dataset by showing the first couple of rows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "001cf514",
      "metadata": {
        "id": "001cf514"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "df8be7f6",
      "metadata": {
        "id": "df8be7f6"
      },
      "source": [
        "The dataset you are looking at contains information about the worldwide monthly temperature anomaly (in degrees C) of the period 1979-2022 relative to the mean global temperature during the period 1951-1980 (`Temperature_anomaly` column). It also lists the concentration of CO2 in the atmosphere measured monthly during this period (in parts per million by volume, or ppmV; `pCO2` column). The first column in your dataset (`Date`) lists the date in dd/mm/yyyy format and the second column numbers the months for easy plotting.\n",
        "\n",
        "This dataset is obtained from the website [__Our World in Data__](https://ourworldindata.org/), which is an excellent source of up-to-date information about climate, food, economic development, biodiversity and other pressing societal issues."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ef846e04",
      "metadata": {
        "id": "ef846e04"
      },
      "source": [
        "__Question 1:__ Now that you have seen this dataset, can you think of a few questions we could solve by applying correlation and/or regression analyses on this data?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57677b08",
      "metadata": {
        "id": "57677b08"
      },
      "source": [
        "__Answer 1:__"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "425ff428",
      "metadata": {
        "id": "425ff428"
      },
      "source": [
        "## Part 1: Correlation\n",
        "\n",
        "For starters, we might be interested in the correlation between atmospheric CO2 concentrations and global temperature.\n",
        "\n",
        "__Question 2:__ Which metric can help us to determine whether there is a correlation between these two variables?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7422b7c0",
      "metadata": {
        "id": "7422b7c0"
      },
      "source": [
        "__Answer 2:__"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "16ad027a",
      "metadata": {
        "id": "16ad027a"
      },
      "source": [
        "Let's try to calculate the Pearson's correlation coefficient between `pCO2` and the `Temperature_anomaly`. We can do thiss with the function `.corr` applied on the two columns in the dataset `df` as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2744df99",
      "metadata": {
        "id": "2744df99"
      },
      "outputs": [],
      "source": [
        "# Calculate Pearson's correlation between pCO2 and temperature anomaly\n",
        "df['pCO2'].corr(df['Temperature_anomaly'], method = 'pearson')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c96578ac",
      "metadata": {
        "id": "c96578ac"
      },
      "source": [
        "__Question 3:__ What do you think of this result? Is there a positive or a negative correlation between these two variables? Do you think the correlation is strong?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4ff9d13",
      "metadata": {
        "id": "d4ff9d13"
      },
      "source": [
        "__Answer 3:__"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f8481633",
      "metadata": {
        "id": "f8481633"
      },
      "source": [
        "Have a good look at the code cell above which you used to calculate the Pearson's correlation coefficient to make sure you understand how it works and what it does. You will be calculating more correlation coefficients in this and later assignments!\n",
        "\n",
        "Ïf you are not sure what is going on here, it can be helpful to look at the documentation for the function (`corr` in the pandas, or `pd` package). You can do that by using the `help()` function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8740f26f",
      "metadata": {
        "id": "8740f26f"
      },
      "outputs": [],
      "source": [
        "# Print the help page for the \"corr\"-function in the pandas library (\"pd\")\n",
        "help(pd.DataFrame.corr)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30f85e4c",
      "metadata": {
        "id": "30f85e4c"
      },
      "source": [
        "That's a lot of information, and much of it may be hard to understand at this stage. Don't panic, the most important thing is that you know how to use this function and how to interpret the output.\n",
        "\n",
        "__Exercise 1:__ To test yourself, you can apply the same function as above to see if there are positive or negative trends in `pCO2` and `Temperature_anomaly` with time in our dataset. In other words: You can test whether there are correlations between the `Month_since_January_1979` variable and either the `pCO2` and `Temperature_anomaly` variables in the dataset. Use the code cell below to do so and answer __Question 3__ for the results of these two correlations as well."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "becd536c",
      "metadata": {
        "id": "becd536c"
      },
      "outputs": [],
      "source": [
        "# Calculate Pearson's correlation between date (in months) and temperature anomaly\n",
        "\n",
        "\n",
        "# Calculate Pearson's correlation between date (in months) and pCO2\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "78fcb252",
      "metadata": {
        "id": "78fcb252"
      },
      "source": [
        "__Answer 3 (for the new correlations):__"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0aac460e",
      "metadata": {
        "id": "0aac460e"
      },
      "source": [
        "__Bonus exercise:__ If you payed close attention to the `help()` output for the `corr` function, you might have spotted that there are multiple ways (`methods`) to calculate correlation between variables. If you are curious, you can try out some of the other correlation methods, such as `kendall` and `spearman` on the pairs of variables in our dataset using the empty code cell below. Is the result very different? What does this tell you about the correlation we found?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3bc4ae4e",
      "metadata": {
        "id": "3bc4ae4e"
      },
      "outputs": [],
      "source": [
        "# Bonus exercise: Try calculating correlation coefficients between variables in df using other methods\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec487388",
      "metadata": {
        "id": "ec487388"
      },
      "source": [
        "## Part 2: Simple linear regression\n",
        "\n",
        "Now that we have discovered some correlations in our dataset, it is time to properly explore our dataset to verify if our correlations are not messed up by *outliers* or if the *form* of the relationship between our variables is not misleading us. We can do this by creating *scatter plots* of our data.\n",
        "\n",
        "An example of a scatter plot showing the relationship between the temperature anomaly and time (in months) is produced by the code below. You can run it using the familiar shortcut (__CTRL + ENTER__ on Windows/Linux and __CMD + ENTER__ on Mac):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77d6747b",
      "metadata": {
        "id": "77d6747b"
      },
      "outputs": [],
      "source": [
        "# Plot temperature anomaly against time\n",
        "plt.scatter(df.Month_since_january_1979, df.Temperature_anomaly, color = 'red', marker = '+')\n",
        "plt.xlabel('# months since January 1979')\n",
        "plt.ylabel('Temperature anomaly (in degrees C)')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "580afc1e",
      "metadata": {
        "id": "580afc1e"
      },
      "source": [
        "Carefully read the code in the cell above and verify that you understand what it does. You will do much more plotting like this in future assignments!\n",
        "\n",
        "Remember, if you are confused about a function (such as `plt.scatter`), you can use the `help()` function to look up its documentation and find out what it does:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "859e6c38",
      "metadata": {
        "id": "859e6c38"
      },
      "outputs": [],
      "source": [
        "help(plt.scatter)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64af3148",
      "metadata": {
        "id": "64af3148"
      },
      "source": [
        "__Exercise 2:__ To test whether you understand how to plot *scatter plots*, create plots of pCO2 vs time and pCO2 vs Temperature anomany in the two code cells below by modifying the code in the cell above used to plot Temperature anomaly vs time. Differentiate these scatter plots from each other by changing plot aesthetics such as the type of plotting symbol (`marker`), the color of the symbols (`col`) or the shading of the symbol (`alpha`). Use the help statement you ran in the previous code cell to guide your coding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c081e01",
      "metadata": {
        "id": "3c081e01"
      },
      "outputs": [],
      "source": [
        "# Plot pCO2 against time\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b342a3e7",
      "metadata": {
        "id": "b342a3e7"
      },
      "outputs": [],
      "source": [
        "# Plot pCO2 against Temperature anomaly\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c35f1f43",
      "metadata": {
        "id": "c35f1f43"
      },
      "source": [
        "We will now explore the shape of the relationship between pCO2 and Temperature using our dataset. To do so, we can run a *simple linear regression* using the __ordinary least squares (OLS)__ algorithm we have discussed in the lectures. We will use the built-in function `smf.ols()` from the `statsmodels` package we loaded at the beginning of the assignment to do this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c74bdc01",
      "metadata": {
        "id": "c74bdc01"
      },
      "outputs": [],
      "source": [
        "regression1 = smf.ols(formula = \"df.Temperature_anomaly ~ df.pCO2\", data = df).fit()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5a54d54",
      "metadata": {
        "id": "b5a54d54"
      },
      "source": [
        "Another new function! Make sure you understand what this one does as well. You know by now how to search for its documentation if you feel lost.\n",
        "\n",
        "The object `regression1` contains all the information about our regression model. Let's print the regression coefficients:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b982a65",
      "metadata": {
        "id": "6b982a65"
      },
      "outputs": [],
      "source": [
        "print('The regression coefficients are:\\n', regression1.params)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4788d6c7",
      "metadata": {
        "id": "4788d6c7"
      },
      "source": [
        "The `\\n` in the code above is used to create a new line, very handy when printing output!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d665b09",
      "metadata": {
        "id": "3d665b09"
      },
      "source": [
        "__Question 4:__ What is the meaning of the slope and intercept in this context?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "466f4df1",
      "metadata": {
        "id": "466f4df1"
      },
      "source": [
        "__Answer 4:__"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c3b491fb",
      "metadata": {
        "id": "c3b491fb"
      },
      "source": [
        "We can now use these coefficients to plot the regression line on top of our data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8c60a92",
      "metadata": {
        "id": "b8c60a92"
      },
      "outputs": [],
      "source": [
        "# Plot the result of simple linear regression between pCO2 and temperature\n",
        "plt.scatter(df.pCO2, df.Temperature_anomaly, color = 'red', marker = '+')\n",
        "plt.xlabel('Atmospheric pCO2 (ppmV)')\n",
        "plt.ylabel('Temperature anomany (degrees C)')\n",
        "plt.plot(df.pCO2, regression1.params[0] + regression1.params[1] * df.pCO2, color = 'blue')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f018ca3c",
      "metadata": {
        "id": "f018ca3c"
      },
      "source": [
        "__Qeustion 5:__ What do you think of this result? Does the regression line capture the relationship between the variables well?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c5265c5",
      "metadata": {
        "id": "0c5265c5"
      },
      "source": [
        "__Answer 5:__"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57185832",
      "metadata": {
        "id": "57185832"
      },
      "source": [
        "To test our relationship, we can calculate the F-value and p-value of the regression. Python can do this for us with one simple command:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4bbc9e4",
      "metadata": {
        "id": "a4bbc9e4"
      },
      "outputs": [],
      "source": [
        "print(regression1.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c35ce667",
      "metadata": {
        "id": "c35ce667"
      },
      "source": [
        "OK, that's a lot of information... Python just calculated a whole bunch of statistical metrics for this regression. The ones we are interested in are the R<sup>2</sup> value (`R-squared`), the F-value (`F-statistic`) and the p-value (or 'probability': `Prob (F-statistic)`). You can also find the slope and intercept in this overview, as well as statistics on how certain we are about them (see `std err` values)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04c18b27",
      "metadata": {
        "id": "04c18b27"
      },
      "source": [
        "__Question 6:__ At a 95% significance level (alpha = 0.05), is this linear relationship statistically significant?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ccf6dd8",
      "metadata": {
        "id": "2ccf6dd8"
      },
      "source": [
        "__Answer 6:__"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0dbb65c2",
      "metadata": {
        "id": "0dbb65c2"
      },
      "source": [
        "__Question 7:__ How much of the variance in our pCO2 vs Temperature_anomaly dataset is explained by this linear relationship?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "59a78257",
      "metadata": {
        "id": "59a78257"
      },
      "source": [
        "__Answer 7:__"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "345698e4",
      "metadata": {
        "id": "345698e4"
      },
      "source": [
        "__Question 8:__ Based on our dataset over the period 1979-2022 and our simple linear regression, how much global warming would you expect if pCO2 increases by 100 ppmV? Can you give an uncertainty for this estimate? (Hint: use the standard error, or `std err` on the relevant regression coefficient)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b58c058",
      "metadata": {
        "id": "1b58c058"
      },
      "source": [
        "__Answer 8:__"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "949682b7",
      "metadata": {
        "id": "949682b7"
      },
      "source": [
        "__Question 9:__ The [__Intergovernmental Panel on Climate Change (IPCC)__](https://www.ipcc.ch/report/ar6/wg1/) considers various __Shared Socioeconomic Pathways__ in their projections for future climate. One of the more moderate scenarios (SSP2-4.5) predicts an atmospheric CO2 concentration of about 500 ppmV in the year 2100. Using the relationship you created in this exercise, what would you expect the temperature anomaly (global warming relative to the period 1951-1980) to be by the end of this century? Is this a realistic estimate? Can you see any problems with this way of projecting future climate?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00dbe2f0",
      "metadata": {
        "id": "00dbe2f0"
      },
      "source": [
        "__Answer 9:__"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82baad1a",
      "metadata": {
        "id": "82baad1a"
      },
      "source": [
        "## Part 3: Polynomial regression\n",
        "\n",
        "To more thoroughly explore the trends in greenhouse gas concentrations and temperature on Earth, we will zoom out a bit and look at a dataset that goes further back in time.\n",
        "\n",
        "__Exercise 3:__ Use the code cell below to load this new dataset, which is called `Lab01b.csv`. You can reuse the code you used at the beginning of the assignment to load `Lab01a.csv`.\n",
        "\n",
        "To prevent confusion between these two datasets, you will need to assign this new dataset a different name from the old one (which was called `df`). We will (rather uncreatively) go with the name `df2` for the remainder of this exercise, but you can give it another name if you like. Just remember that you need to be consistent with your names, otherwise Python will not understand to which object or dataset you are referring to."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81d2490b",
      "metadata": {
        "id": "81d2490b"
      },
      "outputs": [],
      "source": [
        "df2 = pd.read_csv('Lab01b.csv') # Load the second dataset for this assignment in the Jupyter environment."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4613612e",
      "metadata": {
        "id": "4613612e"
      },
      "source": [
        "This dataset contains annual average values of `pCO2` (atmospheric CO2 concentrations; in ppmV), `pCH4` (methane concentration; in ppb), `pN2O` (nitrous oxide concentration; in ppb) and `SST` (sea surface temperature anomalies; in degrees C relative to 1951-1980).\n",
        "\n",
        "__Exercise 4:__ You can inspect this dataset using the `head()` or `print()` commands you used before. Do so using the code cell below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ac8dbab",
      "metadata": {
        "id": "5ac8dbab"
      },
      "outputs": [],
      "source": [
        "# Inspect the new dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb609f71",
      "metadata": {
        "id": "cb609f71"
      },
      "source": [
        "__Question 10:__ What is striking about this dataset?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "acf2a34e",
      "metadata": {
        "id": "acf2a34e"
      },
      "source": [
        "__Answer 10:__"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eacd366e",
      "metadata": {
        "id": "eacd366e"
      },
      "source": [
        "CO2, CH4 and N2O are all greenhouse gases, so we expect them to covary with temperature.\n",
        "\n",
        "__Exercise 5:__ Use the code cell below to calculate the Pearson's correlation coefficient between each of the greenhouse gases and temperature for the time period 1850-2022. You can use the `corr` function and the code you used in Part 1 of this assignment.\n",
        "\n",
        "Do you think the presence of `NaN` values poses a problem? Hint: Check the `help()` entry for the `corr` function you printed above to check this. It is good to be aware of empty values in your dataset, as they can have a big impact on your data analysis!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3623d9ef",
      "metadata": {
        "id": "3623d9ef"
      },
      "outputs": [],
      "source": [
        "# Calculate Pearson's correlation between pCO2 and temperature anomaly\n",
        "\n",
        "\n",
        "# Calculate Pearson's correlation between pCH4 and temperature anomaly\n",
        "\n",
        "\n",
        "# Calculate Pearson's correlation between pN2O and temperature anomaly\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f45160fe",
      "metadata": {
        "id": "f45160fe"
      },
      "source": [
        "__Question 11:__ Which of these greenhouse gas concentrations show a positive correlation with sea surface temperature? Is there a strong correlation?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d51931b4",
      "metadata": {
        "id": "d51931b4"
      },
      "source": [
        "__Answer 11:__"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d27fcb55",
      "metadata": {
        "id": "d27fcb55"
      },
      "source": [
        "We will focus on the CO2 concentration now, and specifically on its trend through time."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9414132d",
      "metadata": {
        "id": "9414132d"
      },
      "source": [
        "__Exercise 6:__ Use your newly gained experience with Python (and the code examples above) to create a plot of pCO2 with time (`Year`) in the code cell below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8042ee9",
      "metadata": {
        "id": "a8042ee9"
      },
      "outputs": [],
      "source": [
        "# Plot pCO2 vs time\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0cbabbf3",
      "metadata": {
        "id": "0cbabbf3"
      },
      "source": [
        "__Exercise 7:__ Repeat the steps in Part 2 of this assignment to calculate a linear regression through the pCO2 time trend and plot the regression result on top of the pCO2 dataset. Use the code cell below.\n",
        "\n",
        "Think carefully about how you name the new regression object! Remember that Python cannot remember two objects of the same name, and make sure you give a new object a name that allows you to remember what is stored in the object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e15a241",
      "metadata": {
        "id": "5e15a241"
      },
      "outputs": [],
      "source": [
        "# Create linear regression between pCO2 and Year in dataset df2\n",
        "\n",
        "# Print the regression coefficients of the new linear regression\n",
        "\n",
        "# Plot pCO2 vs time with the linear regression line on top of the data\n",
        "\n",
        "# Print the regression summary to check the strength and the significance of the linear model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c23c0ecf",
      "metadata": {
        "id": "c23c0ecf"
      },
      "source": [
        "__Question 12:__ Do you think the linear regression approximates the form of the dataset well? What do the R<sup>2</sup>, F and p-value statistics tell you?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f14a48bc",
      "metadata": {
        "id": "f14a48bc"
      },
      "source": [
        "__Answer 12:__"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "38b94149",
      "metadata": {
        "id": "38b94149"
      },
      "source": [
        "The exercise above shows you how important it is to look at scatter plots of your data instead of blindly executing statistical tests. I think you would agree that we can think of better models to approximate the rise of pCO2 since the Industrial Revolution."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40ee288f",
      "metadata": {
        "id": "40ee288f"
      },
      "source": [
        "We will try a __polynomial regression__ to better approximate our pCO2 data. For this to work, we need to import some additional functions from the `sklearn` package, which we will need to preprocess our data for a polynomial regression. You can do so by running the code below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d90eebac",
      "metadata": {
        "id": "d90eebac"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures # Import functions needed for polynomial preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27624b05",
      "metadata": {
        "id": "27624b05"
      },
      "source": [
        "We can use the same OLS function as we used for linear regression to do a polynomial regression, but we need to pre-process our data first. For this we use the `PolynomialFeatures` function we just loaded. We will start by approximating the pCO2 data with a second degree polynomial function. Such a function contains a constant, a first order term and a second order term, yielding a function of the form:\n",
        "\n",
        "$(y = a + b1 * x + b2 * x^2)$\n",
        "\n",
        "Our OLS model will estimate values for `a`, `b1` and `b2`, but we will first transform our independent variable (in this case `Year`) to let Python know we will fit a polynomial function. Use the code below to do this, and inspect the resulting object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d4c6846",
      "metadata": {
        "id": "2d4c6846"
      },
      "outputs": [],
      "source": [
        "x2 = PolynomialFeatures(2, include_bias = False).fit_transform(df2.Year.values.reshape(-1, 1)) # Transform the independent variable Year for a second degree polynomial regression\n",
        "\n",
        "print(x2) # Inspect the resulting dataframe"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "222dda81",
      "metadata": {
        "id": "222dda81"
      },
      "source": [
        "Make sure you understand what happened here. You can always use the `help()` function to understand what `PolynomialFeatures` does, or Google it."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "79a7e9bf",
      "metadata": {
        "id": "79a7e9bf"
      },
      "source": [
        "We will now perform the polynomial regression. This works much like the linear regression, but with the newly created `x2` as a set of independent variables:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6c012bb",
      "metadata": {
        "id": "f6c012bb"
      },
      "outputs": [],
      "source": [
        "polyreg1 = smf.ols('df2.pCO2 ~ x2', data = df2).fit() # Regression of second degree polynomial\n",
        "\n",
        "print(polyreg1.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f548fc3",
      "metadata": {
        "id": "3f548fc3"
      },
      "source": [
        "__Question 13:__ How do the statistics of this polynomial model compare to those of the linear model you calculated before? Which model better describes the data? Which statistical metrics do you use to compare between them?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c50bc847",
      "metadata": {
        "id": "c50bc847"
      },
      "source": [
        "__Answer 13:__"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "98a637d8",
      "metadata": {
        "id": "98a637d8"
      },
      "source": [
        "Test the interpretations you made of the model output in the question above by plotting the result of the polynomial regression on top of the data. You can use the code in the cell below.\n",
        "\n",
        "Note how similar this code is to the code you used to plot the linear regression results earlier in this exercise, and verify that you understand how this code works."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "054cfc1f",
      "metadata": {
        "id": "054cfc1f"
      },
      "outputs": [],
      "source": [
        "# Plot pCO2 vs time with the second degree polynomial regression line on top of the data\n",
        "plt.scatter(df2.Year, df2.pCO2, color = 'red', marker = '+')\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('pCO2 (ppmV)')\n",
        "plt.plot(df2.Year, polyreg1.params[0] + polyreg1.params[1] * df2.Year + polyreg1.params[2] * df2.Year ** 2, color = 'blue')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99769707",
      "metadata": {
        "id": "99769707"
      },
      "source": [
        "__Exercise 8:__ I think we all agree that this result is an improvement, but maybe we can do better. Repeat the process you went through to estimate and plot the second order polynomial regression through the pCO2 dataset, but now create third and fourth order polynomials. Print the statistics for these models and plot them all together on top of the pCO2 data. Again: watch out how you name your objects and think carefully before you copy and paste code. Use the code cell below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0405cc74",
      "metadata": {
        "id": "0405cc74"
      },
      "outputs": [],
      "source": [
        "# Transform the independent variable Year for a third and fourth degree polynomial regression\n",
        "\n",
        "# Create regressions for the third and fourth degree polynomials\n",
        "\n",
        "# Print summaries of third and fourth degree polynomial models\n",
        "\n",
        "# Plot all polynomial models on the data in one plot\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9fc256b",
      "metadata": {
        "id": "f9fc256b"
      },
      "source": [
        "__Question 14:__ What do you think of the result? Do the added polynomial terms improve the model? If so, do you think adding even more terms would be useful here? Can you find an optimum number of polynomial terms to accurately describe the shape of the pCO2 data while preventing overfitting?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c397996",
      "metadata": {
        "id": "8c397996"
      },
      "source": [
        "__Answer 14:__"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61a04416",
      "metadata": {
        "id": "61a04416"
      },
      "source": [
        "__Question 15:__ After what we have learned from looking at a longer timeseries of pCO2, are you still equally confident about your answers to __Question 8 & 9__? If not, what changed your mind?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c7cabffd",
      "metadata": {
        "id": "c7cabffd"
      },
      "source": [
        "__Answer 15:__"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e3bef0a3",
      "metadata": {
        "id": "e3bef0a3"
      },
      "source": [
        "## Part 4: Exponential regression\n",
        "\n",
        "We will now briefly look at the pCO2 trend since 1850 using another type of regression model: exponential regression. We have discussed this type of regression in the lectures, but as a reminder you will find the general function for exponential regression models below:\n",
        "\n",
        "$(y = c * e^{bx})$\n",
        "\n",
        "However, we need to transform this function into its linear form to be able to use OLS. We can do this by taking the natural logarithm on both sides of the equation:\n",
        "\n",
        "$(log{(y)} = log{(c)} + b * x)$\n",
        "\n",
        "Now this is just a simple linear regression of the form $(y = a + bx)$, but with $y$ replaced by $log{(y)}$ and $a$ by $log{(c)}$. To use it, we first need to transform our dependent variable (pCO2) to its natural logarithm. For that, we need to import the `log()` function from the `numpy` package. After the transformation of our pCO2 variable, we can apply the OLS function to perform the linear regression. This code should look quite familiar to you now."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "018c0978",
      "metadata": {
        "id": "018c0978"
      },
      "outputs": [],
      "source": [
        "import numpy as np # Import the numpy package that contains the log-function\n",
        "\n",
        "logCO2 = np.log(df2.pCO2) # Create a new variable that is the natural logarithm of pCO2\n",
        "\n",
        "expreg1 = smf.ols(formula = \"logCO2 ~ df2.Year\", data = df2).fit() # Perform the 'exponential' regression in its linearized form\n",
        "\n",
        "print(expreg1.summary()) # Print the regression summary"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fbf1390e",
      "metadata": {
        "id": "fbf1390e"
      },
      "source": [
        "__Question 16:__ Based on the statistics of the regression model, how well did the exponential regression perform? How does it compare to the linear and polynomial regressions you created before?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ffb45a99",
      "metadata": {
        "id": "ffb45a99"
      },
      "source": [
        "__Answer 16:__"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5550eb1e",
      "metadata": {
        "id": "5550eb1e"
      },
      "source": [
        "__Exercise 9:__ From the regression results, you can now calculate the parameters of the exponental function ($(y = c * e^{bx})$). Use the code cell below to calculate the parameters and plot the result of the exponential regression on top of the pCO2 data.\n",
        "\n",
        "Tip: The `numpy` package contains the function `np.exp` which can be used to calculate e<sup>x</sup> to convert back from the natural logarithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f25aeb1d",
      "metadata": {
        "id": "f25aeb1d"
      },
      "outputs": [],
      "source": [
        "# Calculate the parameter c by taking the natural exponent\n",
        "\n",
        "# Plot the exponential model on top of the pCO2 data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9bcd185",
      "metadata": {
        "id": "c9bcd185"
      },
      "source": [
        "__Question 17:__ What do you think of the result? Can you think of a problem with our exponential model when trying to fit it to this type of data?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "55d7cce6",
      "metadata": {
        "id": "55d7cce6"
      },
      "source": [
        "__Answer 17:__"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "98d30e1d",
      "metadata": {
        "id": "98d30e1d"
      },
      "source": [
        "__Bonus exercise:__ We can probably make our exponential model fit better by modifying our variables `Year` and `pCO2`to relative values. We can do this by subtracting the minimum value in the dataset from all datapoints for both parameters. The function `np.min()` can help us with that:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "082c6eb6",
      "metadata": {
        "id": "082c6eb6"
      },
      "outputs": [],
      "source": [
        "# Create relative pCO2 and Year variables\n",
        "pCO2min = np.min(df2.pCO2) # find the minimum pCO2 value\n",
        "Yearmin = np.min(df2.Year) # find the minimum Year (1850)\n",
        "\n",
        "# Print the results\n",
        "print('The minimum pCO2 value is', pCO2min, 'ppmV')\n",
        "print('The starting Year is', Yearmin, 'AD')\n",
        "\n",
        "pCO2min = 280 # Round the minimum pCO2 down to prevent zeroes in the dataset (log(0) has no solution)\n",
        "\n",
        "pCO2rel = df2.pCO2 - pCO2min\n",
        "Yearrel = df2.Year - Yearmin"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26512e27",
      "metadata": {
        "id": "26512e27"
      },
      "source": [
        "Now repeat the exponential regression you performed above with these modified variables and assess whether it performs better."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0358502c",
      "metadata": {
        "id": "0358502c"
      },
      "outputs": [],
      "source": [
        "# Create a new variable that is the natural logarithm of the modified pCO2 variable\n",
        "\n",
        "# Perform the exponential regression in its linearized form\n",
        "\n",
        "# Print the regression summary\n",
        "\n",
        "# Calculate the parameter c by taking the natural exponent\n",
        "\n",
        "# Plot the exponential model on top of the pCO2 data\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
