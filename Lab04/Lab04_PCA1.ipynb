{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7533bcc",
   "metadata": {},
   "source": [
    "# Lab 04: Factor analysis 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e888e9",
   "metadata": {},
   "source": [
    "Author: **N.J. de Winter** (*n.j.de.winter@vu.nl*)<br>\n",
    "Assitant Professor Vrije Universiteit Amsterdam<br>\n",
    "Statistics and Data Analysis Course\n",
    "\n",
    "Modified after: Trauth, Martin H., et al. MATLAB recipes for earth sciences. Vol. 34. Berlin: Springer, 2007."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279121ed",
   "metadata": {},
   "source": [
    "\n",
    "## Learning goals:\n",
    "\n",
    "* Apply and improve your knowledge of Python and Jupyter\n",
    "* Get famliar with factor analysis\n",
    "    * Learn to run a Principle Component Analysis (PCA) in Python\n",
    "    * Understand and apply tools to assess whether the *variables* in a dataset can be reduced\n",
    "    * Interpret *scores* and *loadings* and *eigenvalues* of a PCA result\n",
    "* Develop a feeling for how statistical tools can help you, but you still require *your interpretation* to draw conclusions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e040acc6",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "In this lab, we will start working with **Factor analysis**. More specifically, we will apply a technique called **Principle Component Analysis** to a dataset to test whether the information in the data can be *reduced* by finding a small set of *components* which replace the *variables* in the dataset while containing (almost) the same information.\n",
    "\n",
    "This all sounds quite technical, and that is because it is. **Factor analysis can be a hard concept to wrap your head around**, and it is normal to be confused about it in the beginning. However, it is also a very powerful tool for data reduction, which plays an important role in modern science and in our society as a whole and is used for a surprising number of things!\n",
    "\n",
    "This is why we spend two labs practicing it. Do not dispair, we will go through this step by step so you will have plenty of time to practice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca10642f",
   "metadata": {},
   "source": [
    "We will start by loading the packages we will need. You know how to do this by now, so we will not give you the code any more from now on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200e607b",
   "metadata": {},
   "source": [
    "**Exercise 1:** Load the `numpy` package and the `pyplot` package (part of `matplotlib`), import the `stats` package from the `scipy` library  and `import` the function `PCA` from the `decomposition` package which is part of `sklearn`.  Don't forget to add the statement you used before to allow plots to be visualized in Jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe6e20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The 'numpy' package contains some handy functions\n",
    "# The 'matplotlib' package contains tools needed to plot our data and results\n",
    "# The 'stats' package contains statistical functions\n",
    "# Load the PCA function from the decomposition package in sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fab4fe4",
   "metadata": {},
   "source": [
    "In this lab, we are going to use the same dataset as in *Lab 03*. You know how to load this data by now (if not, have a sneak peak at the previous lab). Don't forget that if you are using Spyder, you need to first define your working directory, and that if you are using Jupyter, you need to move the dataset into the same folder as your notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84db3913",
   "metadata": {},
   "source": [
    "**Exercise 2:** Load *Lab03.txt* in Python and explore the data to familiarize yourself again with its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef448d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "# inspect data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6573e28",
   "metadata": {},
   "source": [
    "If a `print()` of the dataset confuses you, recall again type of data is in this dataset. You should be able to answer the questions below easily if you do."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82d2802",
   "metadata": {},
   "source": [
    "**Question 1:** What do the *observations* in this dataset represent?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a62fe99",
   "metadata": {},
   "source": [
    "**Answer 1:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8657ad8",
   "metadata": {},
   "source": [
    "**Question 2:** What do the *variables* in this dataset represent?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c17e579",
   "metadata": {},
   "source": [
    "**Answer 2:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4bc41b",
   "metadata": {},
   "source": [
    "**Question 3:** What type of information does each datapoint in the dataset contain? What is the unit of this data? What is the minimum and maximum value a datapoint can have?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1feda311",
   "metadata": {},
   "source": [
    "**Answer 3:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6e39a0",
   "metadata": {},
   "source": [
    "Before we dive into factor analysis, it is very important that we recap the structure of the data and explore the correlations between variables we can already observe before doing \"fancy\" statistics. The easiest way to do this is to create a correlation matrix and to visualize the correlations between the variables in some way. Luckily, you have already learned how to do that in the previous Lab, so you can recycle the code from **Lab03**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a224ef",
   "metadata": {},
   "source": [
    "**Exercise 3:** Calculate the correlation matrix for the dataset and plot the correlations using a heatmap (use the `imshow` function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63aca9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a correlation matrix of the mineral content\n",
    "\n",
    "\n",
    "# Create a vector of variable names (minerals)\n",
    "\n",
    "\n",
    "# Flip the correlation matrix for plotting:\n",
    "\n",
    "\n",
    "# Plot the correlation matrix with colors representing the degree of correlation:\n",
    "\n",
    "\n",
    "# Add a title to the graph\n",
    "\n",
    "\n",
    "# Add the mineral labels:\n",
    "\n",
    "\n",
    "# Display the colorbar as a legend:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b01fc13",
   "metadata": {},
   "source": [
    "**Question 4:** Which (groups of) minerals are highly correlated to each other?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d89cc80",
   "metadata": {},
   "source": [
    "**Answer 4:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc566f7",
   "metadata": {},
   "source": [
    "This is a typical example of a dataset in which the variables contain a lot of overlap in terms of information. The fact that some variables are so highly correlated shows us that they teach us (almost) the same thing about our samples. From a statistical and data science point of view, this is very **inefficient**! We can likely **summarize the information contained in this dataset using a small number of more smartly chosen variables**. This is the goal of factor analysis. Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10da060",
   "metadata": {},
   "source": [
    "We will use the `PCA` function to perform a Principle Component Analysis on our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b8f001",
   "metadata": {},
   "source": [
    "**Exercise 4:** First, have a look at the `PCA` function using the `help()` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c332588b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "43eb19ca",
   "metadata": {},
   "source": [
    "OK, that is a lot of information. Don't worry, you don't need to understand all the options you have with this function. Sometimes, it is easier to look at the `help()` for a function online. The `help`-generated webpage for a function contains the same information as you have just exported using the `help()` function, but it is nicely formatted and easier to read. [This is the help page for the `PCA` function](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html) \n",
    "\n",
    "What you need to keep in mind is that the syntax (the way you call the function in Python) is a bit different from what you are used to so far. It works as follows: First you create an object that contains the settings you want for your PCA. Then you `fit` that object on your data to get PCA results. We'll go through it step by step below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b76e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA() # We first call the PCA function to create our PCA object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1349e763",
   "metadata": {},
   "source": [
    "Note that we did not specify any settings for our PCA, which means we are using the default settings. You can find out what these are in the `help()` documentation. If you run a PCA, always make sure your data is normalized. You can do this with the `zscore` function from the `stats` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0edc351",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = stats.zscore(data, axis=0) # Normalize dataset, resulting in equal variance for all minerals\n",
    "\n",
    "scores = pca.fit_transform(data) # Now we apply the new pca object to our data to get our PCA scores\n",
    "print(scores) # Examine the scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9897ab63",
   "metadata": {},
   "source": [
    "The *scores* give you the values for each *principle component* for each sample. Remember that the *principle components* can be regarded as the \"new *variables*\". The *loadings* of the PCA are stored in the variable `pca.components_`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3294cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pca.components_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57ffd65",
   "metadata": {},
   "source": [
    "In order to obtain a matrix in which columns represent the principal component *loadings* in descending order of explained variability, we need to transpose the `pca.components_` variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae7e94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loadings = np.transpose(pca.components_) # Create a new object with loadings in columns ordered from highest to least amount of explained variance.\n",
    "print(loadings) # Examine the result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a45ce4",
   "metadata": {},
   "source": [
    "**Question 5:** What type of information can you get from the loadings of your PCA? How can you interpret them?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68af3f55",
   "metadata": {},
   "source": [
    "**Answer 5:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc09953e",
   "metadata": {},
   "source": [
    "Let’s plot the loadings of the first principal component. In the code below, note that we use the first column of the `loadings` matrix (`loadings[:, 0]`) to isolate the loadings for the first principle component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614178e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(1,10) # Create a vector with numbers for the variables\n",
    "plt.figure(2)\n",
    "plt.plot(a, loadings[:, 0], 'o', clip_on = False) # Plot scatter plot of loadings for each variable.\n",
    "plt.plot(a, np.zeros(np.size(a)), color = 'red') # Plot a horizontal red line indicating loading of zero\n",
    "for i, label in enumerate(minerals): # Loop through the variable names (minerals)\n",
    "    plt.text(a[i] + 0.2, loadings[:, 0][i], label, fontsize = 8) # Plot the names of the variables next to the points\n",
    "plt.xlim([1, 9]) # Set the limits for the horizontal axis\n",
    "plt.ylim([-1, 1]) # Set the limits for the vertical axis\n",
    "plt.title('PC 1') # Set the plot title\n",
    "plt.show() # Show the plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc3aea6",
   "metadata": {},
   "source": [
    "**Question 6:** Which variables load highly on the first principal component?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e874d4c1",
   "metadata": {},
   "source": [
    "**Answer 6:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f84c138",
   "metadata": {},
   "source": [
    "**Question 7:** Knowing what you do about this dataset (refer back to **Lab03** if you don't remember!), what might principle component 1 represent?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9311543",
   "metadata": {},
   "source": [
    "**Answer 7:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8942def",
   "metadata": {},
   "source": [
    "**Exercise 5:** Now repeat the process for Principle Component 2 and make your interpretation like you did for the first one by answering **Question 8** and **Question 9** below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62132513",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6dea9a6c",
   "metadata": {},
   "source": [
    "**Question 8:** Which variables load strongly on principle component 2?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5598490e",
   "metadata": {},
   "source": [
    "**Answer 8:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a710081",
   "metadata": {},
   "source": [
    "**Question 9:** What might principle component 2 represent?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c598140",
   "metadata": {},
   "source": [
    "**Answer 9:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5a4274",
   "metadata": {},
   "source": [
    "Now we will make a cross plot of the loadings of the first two principle components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b13396",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(4)\n",
    "plt.scatter(loadings[:, 0], loadings[:, 1]) # Plot loadings of PC1 vs PC2\n",
    "plt.xlim([-0.6, 0.8]) # Set horizontal axis limits\n",
    "plt.ylim([-0.6, 0.8]) # Set vertical axis limits\n",
    "plt.axhline(color = 'r') # Create red horizontal line for y = 0\n",
    "plt.axvline(color = 'r') # Create red vertical line for x = 0\n",
    "for i, label in enumerate(minerals):\n",
    "    plt.text(loadings[:, 0][i] + 0.02, loadings[:, 1][i], label, fontsize = 8) # Label the variables\n",
    "plt.xlabel('PC1 loadings') # Provide label for horizontal axis\n",
    "plt.ylabel('PC2 loadings') # Provide label for vertical axis\n",
    "plt.show() # Show the plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbf14cc",
   "metadata": {},
   "source": [
    "**Question 10:** What can we learn from this scatterplot? Does the result surprise you after what you have learned in Lab03 and from your correlation matrix?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aebc938",
   "metadata": {},
   "source": [
    "**Answer 10:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed1da98",
   "metadata": {},
   "source": [
    "We can also make a scatter plot of the *scores* of the samples (observations) for PC1 and PC2 instead of the *loadings*. The `scores` variable gives the principal component *scores* for all samples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734fd65b",
   "metadata": {},
   "source": [
    "**Exercise 6:** Try to make this scores scatterplot yourself for PC1 vs PC2.\n",
    "\n",
    "*Tip*: You can recycle much of the code used for the crossplot above, but be careful with the labels you use for the plot and the limits of your axes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf2f7c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "210e329e",
   "metadata": {},
   "source": [
    "**Question 11:** What does this plot tell you about the different samples, especially if you compare it to the loadings crossplot?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63e378d",
   "metadata": {},
   "source": [
    "**Answer 11:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62488ea4",
   "metadata": {},
   "source": [
    "So far, we have only looked at the first two principle components, but there are more. In fact, a PCA always initially yields a number of components equal to the number of variables in the dataset. However, the amount of variance in the dataset that is explained by a component decreases down the list. To keep track of how much variance each component explains (and therefore how important it is), we can calculate the *eigenvalues* of the components. We do this by dividing the variance explained by each component by the total amount of variance in the dataset, and we multiply by 100% to make the numbers easier to interpret:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87934234",
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_explained = 100 * pca.explained_variance_ / np.sum(pca.explained_variance_)\n",
    "print(percent_explained)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87509a17",
   "metadata": {},
   "source": [
    "To make this result easy to interpret, we can plot these eigenvalues in a scatterplot. The code below should be quite familiar to you now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcbc3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(1, 10) # Create a vector with numbers for the components\n",
    "plt.figure(6)\n",
    "plt.plot(a, percent_explained, 'o', clip_on = False) # Plot scatter plot of eigenvalues for each component.\n",
    "plt.xlim([1, 9]) # Set the limits for the horizontal axis\n",
    "plt.ylim([0, 100]) # Set the limits for the vertical axis\n",
    "plt.xlabel('PCA component') # Provide label for horizontal axis\n",
    "plt.ylabel('Percent of variance explained') # Provide label for vertical axis\n",
    "plt.title('Eigenvalues per component') # Set the plot title\n",
    "plt.show() # Show the plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19423e6d",
   "metadata": {},
   "source": [
    "Since the entire goal of factor analysis is to **reduce** the data, we want to get rid of those principle components that explain (almost) no variance and only keep the components that are important enough."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db088ff8",
   "metadata": {},
   "source": [
    "**Question 12:** Where would you draw the line? How many components would you keep? And why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3ab783",
   "metadata": {},
   "source": [
    "**Answer 12:**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
